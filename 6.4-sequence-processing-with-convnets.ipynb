{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4-tf'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence processing with convnets\n",
    "\n",
    "This notebook contains the code samples found in Chapter 6, Section 4 of [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python?a_aid=keras&a_bid=76564dff). Note that the original text features far more content, in particular further explanations and figures: in this notebook, you will only find source code and related comments.\n",
    "\n",
    "<img src=\"https://github.com/soo-pecialist/Deep_Learning_with_Python/blob/master/imgages/Figure6_26.png?raw=true\" alt=\"Figure 6-26\" width=500>\n",
    "\n",
    "\n",
    "## Implementing a 1D convnet\n",
    "\n",
    "In Keras, you would use a 1D convnet via the `Conv1D` layer, which has a very similar interface to `Conv2D`. It takes as input 3D tensors \n",
    "with shape `(samples, time, features)` and also returns similarly-shaped 3D tensors. The convolution window is a 1D window on the temporal \n",
    "axis, axis 1 in the input tensor.\n",
    "\n",
    "Let's build a simple 2-layer 1D convnet and apply it to the IMDB sentiment classification task that you are already familiar with.\n",
    "\n",
    "As a reminder, this is the code for obtaining and preprocessing the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 500)\n",
      "x_test shape: (25000, 500)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "max_features = 10_000  # number of words to consider as features\n",
    "max_len = 500  # cut texts after this number of words (among top max_features most common words)\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_len)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1D convnets are structured in the same way as their 2D counter-parts that you have used in Chapter 5: they consist of a stack of `Conv1D` \n",
    "and `MaxPooling1D` layers, eventually ending in either a global pooling layer or a `Flatten` layer, turning the 3D outputs into 2D outputs, \n",
    "allowing to add one or more `Dense` layers to the model, for classification or regression.\n",
    "\n",
    "One difference, though, is the fact that we can afford to use larger convolution windows with 1D convnets. Indeed, with a 2D convolution \n",
    "layer, a 3x3 convolution window contains 3*3 = 9 feature vectors, but with a 1D convolution layer, a convolution window of size 3 would \n",
    "only contain 3 feature vectors. We can thus easily afford 1D convolution windows of size 7 or 9.\n",
    "\n",
    "This is our example 1D convnet for the IMDB dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 500, 128)          1280000   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 494, 32)           28704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 92, 32)            7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,315,937\n",
      "Trainable params: 1,315,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 20s 1ms/sample - loss: 0.7129 - acc: 0.5372 - val_loss: 0.6821 - val_acc: 0.5818\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 20s 1ms/sample - loss: 0.6575 - acc: 0.6924 - val_loss: 0.6518 - val_acc: 0.6832\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 21s 1ms/sample - loss: 0.6003 - acc: 0.7866 - val_loss: 0.5766 - val_acc: 0.7660\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 22s 1ms/sample - loss: 0.4841 - acc: 0.8263 - val_loss: 0.4557 - val_acc: 0.8200\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 21s 1ms/sample - loss: 0.3826 - acc: 0.8589 - val_loss: 0.3958 - val_acc: 0.8442\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 21s 1ms/sample - loss: 0.3269 - acc: 0.8805 - val_loss: 0.3982 - val_acc: 0.8530\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 22s 1ms/sample - loss: 0.2926 - acc: 0.8978 - val_loss: 0.4216 - val_acc: 0.8596\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 21s 1ms/sample - loss: 0.2592 - acc: 0.9094 - val_loss: 0.4611 - val_acc: 0.8522\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 22s 1ms/sample - loss: 0.2347 - acc: 0.9204 - val_loss: 0.4345 - val_acc: 0.8698\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 22s 1ms/sample - loss: 0.2109 - acc: 0.9291 - val_loss: 0.4535 - val_acc: 0.8722\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(max_features, 128, input_length=max_len))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(5))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=RMSprop(lr=1e-4),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are our training and validation results: validation accuracy is somewhat lower than that of the LSTM we used two sections ago, but \n",
    "runtime is faster, both on CPU and GPU (albeit the exact speedup will vary greatly depending on your exact configuration). At that point, \n",
    "we could re-train this model for the right number of epochs (8), and run it on the test set. This is a convincing demonstration that a 1D \n",
    "convnet can offer a fast, cheap alternative to a recurrent network on a word-level sentiment classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.ylim(0.0, 1.0)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining CNNs and RNNs to process long sequences\n",
    "\n",
    "\n",
    "Because 1D convnets process input patches independently, they are not sensitive to the order of the timesteps (beyond a local scale, the \n",
    "size of the convolution windows), unlike RNNs. Of course, in order to be able to recognize longer-term patterns, one could stack many \n",
    "convolution layers and pooling layers, resulting in upper layers that would \"see\" long chunks of the original inputs -- but that's still a \n",
    "fairly weak way to induce order-sensitivity. **One way to evidence this weakness** is to try 1D convnets on the temperature forecasting problem \n",
    "from the previous section, where order-sensitivity was key to produce good predictions. Let's see:\n",
    "\n",
    "#### Case of 1d convnet not working great"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We reuse the following variables defined in the last section:\n",
    "# float_data, train_gen, val_gen, val_steps\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data_dir = '/Users/soohyeonkim/GoogleDrive/Coding/DeepLearning/DLwPy/inplay'\n",
    "fname = os.path.join(data_dir, 'data/download/jena_climate_2009_2016.csv')\n",
    "\n",
    "f = open(fname)\n",
    "data = f.read()\n",
    "f.close()\n",
    "\n",
    "lines = data.split('\\n')\n",
    "header = lines[0].split(',')\n",
    "lines = lines[1:]\n",
    "\n",
    "float_data = np.zeros((len(lines), len(header) - 1))\n",
    "for i, line in enumerate(lines):\n",
    "    values = [float(x) for x in line.split(',')[1:]]\n",
    "    float_data[i, :] = values\n",
    "    \n",
    "mean = float_data[:200000].mean(axis=0)\n",
    "float_data -= mean\n",
    "std = float_data[:200000].std(axis=0)\n",
    "float_data /= std\n",
    "\n",
    "def generator(data, lookback, delay, min_index, max_index,\n",
    "              shuffle=False, batch_size=128, step=6):\n",
    "    \n",
    "    ### we want [-23h, -22h, ..., now] (24 hr) range. that's why we set index accordingly. \n",
    "    ### keep in mind we use range(min_index, max_index) which gives [min_index, max_index) range\n",
    "    ### to match our time range goal, we need to be careful.\n",
    "    \n",
    "    if max_index is None: # use all datay\n",
    "        max_index = len(data) - delay # we include current time \n",
    "    min_index += 1 # we want data since 24 hr ago \n",
    "    i = min_index + lookback\n",
    "    \n",
    "    \n",
    "    while 1: # infinite loop\n",
    "        if shuffle:\n",
    "            row_idxs = np.random.randint(\n",
    "                min_index + lookback, max_index, size=batch_size) # +1 because range is [a, b)\n",
    "        else:\n",
    "            if i + batch_size >= max_index: # if overflow, reset to the origin\n",
    "                i = min_index + lookback\n",
    "            row_idxs = np.arange(i, min(i + batch_size, max_index)) # same reason\n",
    "            i += len(row_idxs)\n",
    "\n",
    "        samples = np.zeros((len(row_idxs), # batch size\n",
    "                           lookback // step, # sample every hour (60 min)\n",
    "                           data.shape[-1])) # take all attributes\n",
    "        targets = np.zeros((len(row_idxs),)) # batch size\n",
    "        \n",
    "        for j, row in enumerate(row_idxs): # get indexes of current batch and global batch\n",
    "            indices = range(row - lookback, row, step) # global indexs: \n",
    "                                                           # [current-lookback, current-lookback+1hr, ...  current]\n",
    "            samples[j] = data[indices] # ((lookback//step), # features)\n",
    "            targets[j] = data[row + delay][1] # temperature in 24 hours from \"now\"\n",
    "        yield samples, targets\n",
    "        \n",
    "lookback = 1_440\n",
    "step = 6\n",
    "delay = 144\n",
    "batch_size = 128\n",
    "\n",
    "train_gen = generator(float_data, # original sequence data\n",
    "                      lookback=lookback, # how far reference goes back \n",
    "                      delay=delay, # where to look in the future\n",
    "                      min_index=0, # start \n",
    "                      max_index=200_000, # end #first 200_000 time steps\n",
    "                      shuffle=True, # shuffle : True\n",
    "                      step=step, # get referece every step time\n",
    "                      batch_size=batch_size)\n",
    "\n",
    "# note that no shuffling for validation and test data\n",
    "val_gen = generator(float_data,\n",
    "                    lookback=lookback,\n",
    "                    delay=delay,\n",
    "                    min_index=200_001,\n",
    "                    max_index=300_000, # next 100_000 time steps\n",
    "                    step=step,\n",
    "                    batch_size=batch_size)\n",
    "test_gen = generator(float_data,\n",
    "                     lookback=lookback,\n",
    "                     delay=delay,\n",
    "                     min_index=300_001,\n",
    "                     max_index=None, # look at the remainder\n",
    "                     step=step,\n",
    "                     batch_size=batch_size)\n",
    "\n",
    "# This is how many steps to draw from `val_gen`\n",
    "# in order to see the whole validation set:\n",
    "val_steps = (300_000 - 200_001 - lookback) // batch_size\n",
    "\n",
    "# This is how many steps to draw from `test_gen`\n",
    "# in order to see the whole test set:\n",
    "test_steps = (len(float_data) - 300_001 - lookback) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "500/500 [==============================] - 40s 79ms/step - loss: 0.4173 - val_loss: 0.4325\n",
      "Epoch 2/20\n",
      "500/500 [==============================] - 39s 77ms/step - loss: 0.3637 - val_loss: 0.4427\n",
      "Epoch 3/20\n",
      "500/500 [==============================] - 50s 100ms/step - loss: 0.3413 - val_loss: 0.4668\n",
      "Epoch 4/20\n",
      "500/500 [==============================] - 46s 92ms/step - loss: 0.3241 - val_loss: 0.4353\n",
      "Epoch 5/20\n",
      "500/500 [==============================] - 45s 91ms/step - loss: 0.3136 - val_loss: 0.4774\n",
      "Epoch 6/20\n",
      "500/500 [==============================] - 42s 84ms/step - loss: 0.3059 - val_loss: 0.4534\n",
      "Epoch 7/20\n",
      "500/500 [==============================] - 44s 87ms/step - loss: 0.2968 - val_loss: 0.4537\n",
      "Epoch 8/20\n",
      "500/500 [==============================] - 42s 84ms/step - loss: 0.2907 - val_loss: 0.4828\n",
      "Epoch 9/20\n",
      "500/500 [==============================] - 44s 88ms/step - loss: 0.2844 - val_loss: 0.4873\n",
      "Epoch 10/20\n",
      "500/500 [==============================] - 44s 87ms/step - loss: 0.2815 - val_loss: 0.4960\n",
      "Epoch 11/20\n",
      "500/500 [==============================] - 41s 82ms/step - loss: 0.2766 - val_loss: 0.4532\n",
      "Epoch 12/20\n",
      "500/500 [==============================] - 40s 81ms/step - loss: 0.2730 - val_loss: 0.4590\n",
      "Epoch 13/20\n",
      "500/500 [==============================] - 37s 75ms/step - loss: 0.2675 - val_loss: 0.4576\n",
      "Epoch 14/20\n",
      "500/500 [==============================] - 35s 70ms/step - loss: 0.2656 - val_loss: 0.4789\n",
      "Epoch 15/20\n",
      "500/500 [==============================] - 36s 71ms/step - loss: 0.2634 - val_loss: 0.4925\n",
      "Epoch 16/20\n",
      "500/500 [==============================] - 35s 71ms/step - loss: 0.2618 - val_loss: 0.4888\n",
      "Epoch 17/20\n",
      "500/500 [==============================] - 35s 70ms/step - loss: 0.2570 - val_loss: 0.4787\n",
      "Epoch 18/20\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.2559 - val_loss: 0.4763\n",
      "Epoch 19/20\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.2518 - val_loss: 0.4780\n",
      "Epoch 20/20\n",
      "500/500 [==============================] - 49s 98ms/step - loss: 0.2506 - val_loss: 0.4744\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Conv1D(32, 5, activation='relu',\n",
    "                        input_shape=(None, float_data.shape[-1])))\n",
    "model.add(layers.MaxPooling1D(3))\n",
    "model.add(layers.Conv1D(32, 5, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(3))\n",
    "model.add(layers.Conv1D(32, 5, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "model.compile(optimizer=RMSprop(), loss='mae')\n",
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch=500,\n",
    "                              epochs=20,\n",
    "                              validation_data=val_gen,\n",
    "                              validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are our training and validation Mean Absolute Errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(loss))\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The validation MAE stays in the low 0.40s: we cannot even beat our common-sense baseline using the small convnet. Again, this is because \n",
    "our convnet looks for patterns anywhere in the input timeseries, and has no knowledge of the temporal position of a pattern it sees (e.g. \n",
    "towards the beginning, towards the end, etc.). Since more recent datapoints should be interpreted differently from older datapoints in the \n",
    "case of this specific forecasting problem, the convnet fails at producing meaningful results here. This limitation of convnets was not an \n",
    "issue on IMDB, because patterns of keywords that are associated with a positive or a negative sentiment will be informative independently \n",
    "of where they are found in the input sentences.\n",
    "\n",
    "One strategy to combine the speed and lightness of convnets with the order-sensitivity of RNNs is to use a 1D convnet as a preprocessing \n",
    "step before a RNN. This is especially beneficial when dealing with sequences that are so long that they couldn't realistically be processed \n",
    "with RNNs, e.g. sequences with thousands of steps. The convnet will turn the long input sequence into much shorter (downsampled) sequences \n",
    "of higher-level features. This sequence of extracted features then becomes the input to the RNN part of the network.\n",
    "\n",
    "<img src=\"https://github.com/soo-pecialist/Deep_Learning_with_Python/blob/master/imgages/Figure6_30.png?raw=true\" alt=\"Figure 6-30\" width=500>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This technique is not seen very often in research papers and practical applications, possibly because it is not very well known. **It is very effective and ought to be more common**. Let's try this out on the temperature forecasting dataset. Because this strategy allows us to \n",
    "manipulate much longer sequences, we could either look at data from further back (by increasing the `lookback` parameter of the data \n",
    "generator), or look at high-resolution timeseries (by decreasing the `step` parameter of the generator). Here, we will chose (somewhat \n",
    "arbitrarily) to use a **`step` twice smaller, resulting in twice longer timeseries, where the weather data is being sampled at a rate of one point per 30 minutes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This was previously set to 6 (one point per hour).\n",
    "# Now 3 (one point per 30 min).\n",
    "step = 3 # changed from 6\n",
    "lookback = 720  # changed: 10 days (1440) -> 5 days\n",
    "delay = 144 # Unchanged: 24 hrs later\n",
    "batch_size = 128\n",
    "\n",
    "train_gen = generator(float_data,\n",
    "                      lookback=lookback,\n",
    "                      delay=delay,\n",
    "                      min_index=0,\n",
    "                      max_index=200_000,\n",
    "                      shuffle=True,\n",
    "                      step=step,\n",
    "                      batch_size=batch_size)\n",
    "val_gen = generator(float_data,\n",
    "                    lookback=lookback,\n",
    "                    delay=delay,\n",
    "                    min_index=200_001,\n",
    "                    max_index=300_000,\n",
    "                    step=step,\n",
    "                    batch_size=batch_size)\n",
    "test_gen = generator(float_data,\n",
    "                     lookback=lookback,\n",
    "                     delay=delay,\n",
    "                     min_index=300_001,\n",
    "                     max_index=None,\n",
    "                     step=step,\n",
    "                     batch_size=batch_size)\n",
    "val_steps = (300_000 - 200_001 - lookback) // batch_size\n",
    "test_steps = (len(float_data) - 300_001 - lookback) // batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our model, starting with two `Conv1D` layers and following-up with a `GRU` layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookback//step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_5 (Conv1D)            (None, None, 32)          2272      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, None, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, None, 32)          5152      \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 32)                6336      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 13,793\n",
      "Trainable params: 13,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "500/500 [==============================] - 481s 962ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/20\n",
      "430/500 [========================>.....] - ETA: 39s - loss: nan"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4c92fc26935a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                               validation_steps=val_steps)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[1;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[1;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[1;32m    975\u001b[0m                  outputs['metrics'])\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    312\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    250\u001b[0m               \u001b[0moutput_loss_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_loss_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m               \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m               training=training))\n\u001b[0m\u001b[1;32m    253\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         raise ValueError('The model cannot be run '\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_model_loss\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m   \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m   \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    254\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[0;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    706\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m    707\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m           \u001b[0;31m# Compute outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m           \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m    337\u001b[0m           \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m           \u001b[0mtime_major\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_major\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m           zero_output_for_mask=self.zero_output_for_mask)\n\u001b[0m\u001b[1;32m    340\u001b[0m       \u001b[0;31m# This is a dummy tensor for testing purpose.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m       \u001b[0mruntime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_runtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_RUNTIME_UNKNOWN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36mrnn\u001b[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask)\u001b[0m\n\u001b[1;32m   4033\u001b[0m     \u001b[0;31m# the value is discarded.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4034\u001b[0m     output_time_zero, _ = step_function(\n\u001b[0;32m-> 4035\u001b[0;31m         input_time_zero, tuple(initial_states) + tuple(constants))\n\u001b[0m\u001b[1;32m   4036\u001b[0m     output_ta = tuple(\n\u001b[1;32m   4037\u001b[0m         tensor_array_ops.TensorArray(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(cell_inputs, cell_states)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m       last_output, outputs, states = K.rnn(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, states, training)\u001b[0m\n\u001b[1;32m   1631\u001b[0m     \u001b[0mdp_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dropout_mask_for_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m     rec_dp_mask = self.get_recurrent_dropout_mask_for_cell(\n\u001b[0;32m-> 1633\u001b[0;31m         h_tm1, training, count=3)\n\u001b[0m\u001b[1;32m   1634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1635\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mget_recurrent_dropout_mask_for_cell\u001b[0;34m(self, inputs, training, count)\u001b[0m\n\u001b[1;32m   1095\u001b[0m           count=count)\n\u001b[1;32m   1096\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eager_recurrent_dropout_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrec_dp_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1098\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recurrent_dropout_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrec_dp_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   2272\u001b[0m     \u001b[0;31m# if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2273\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2274\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__delattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2275\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2276\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__delattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2217\u001b[0m     \u001b[0;31m# should clean it out to avoid leaking memory. First we check if there are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2218\u001b[0m     \u001b[0;31m# other attributes referencing it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2219\u001b[0;31m     \u001b[0mreference_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_obj_reference_counts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2220\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexisting_value\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreference_counts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2221\u001b[0m       \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutoTrackable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__delattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_obj_reference_counts\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2186\u001b[0m     \u001b[0;34m\"\"\"A dictionary counting the number of attributes referencing an object.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2187\u001b[0m     self._maybe_create_attribute('_obj_reference_counts_dict',\n\u001b[0;32m-> 2188\u001b[0;31m                                  object_identity.ObjectIdentityDictionary())\n\u001b[0m\u001b[1;32m   2189\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_obj_reference_counts_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/util/object_identity.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    109\u001b[0m   \"\"\"\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Conv1D(32, 5, activation='relu',\n",
    "                        input_shape=(None, float_data.shape[-1])))\n",
    "model.add(layers.MaxPooling1D(3))\n",
    "model.add(layers.Conv1D(32, 5, activation='relu'))\n",
    "model.add(layers.GRU(32, dropout=0.1, recurrent_dropout=0.5))\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=RMSprop(), loss='mae')\n",
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch=500, # 500 * 128\n",
    "                              epochs=20,\n",
    "                              validation_data=val_gen,\n",
    "                              validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(loss))\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Judging from the validation loss, this setup is not quite as good as the regularized GRU alone, but it's significantly faster. It is \n",
    "looking at twice more data, which in this case doesn't appear to be hugely helpful, but may be important for other datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping up\n",
    "\n",
    "Here's what you should take away from this section:\n",
    "\n",
    "* In the same way that 2D convnets perform well for processing visual patterns in 2D space, 1D convnets perform well for processing \n",
    "temporal patterns. They offer a faster alternative to RNNs on some problems, in particular NLP tasks.\n",
    "* Typically 1D convnets are structured much like their 2D equivalents from the world of computer vision: they consist of stacks of `Conv1D` \n",
    "layers and `MaxPooling1D` layers, eventually ending in a global pooling operation or flattening operation.\n",
    "* Because RNNs are extremely expensive for processing very long sequences, but 1D convnets are cheap, it can be a good idea to use a 1D \n",
    "convnet as a preprocessing step before a RNN, shortening the sequence and extracting useful representations for the RNN to process.\n",
    "\n",
    "One useful and important concept that we will not cover in these pages is that of 1D convolution with dilated kernels."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
